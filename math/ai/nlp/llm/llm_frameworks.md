# LLM Frameworks

## Llama Index

## LLM Hosting Frameworks

### SGLang

### Ollama and llama.cpp

### vLLM

vLLM (Very Large Language Model) is a framework designed **to optimize the deployment and inference** of large language models (LLMs).

It features two advantages:

* Good memory optimization strategies, such as *PagedAttention*, to minimize memory usage during inference.
* Designed to scale across multiple GPUs and nodes

### Transformers

### KTransformers
