# LLM Frameworks

## LangChain

### LangServe

### LangFuse

### LangKit

### LangCheck

## Llama Index

## Ollama and llama.cpp

## vLLM

vLLM (Very Large Language Model) is a framework designed **to optimize the deployment and inference** of large language models (LLMs).

It features two advantages:

* Good memory optimization strategies, such as *PagedAttention*, to minimize memory usage during inference.
* Designed to scale across multiple GPUs and nodes

## Transformers
